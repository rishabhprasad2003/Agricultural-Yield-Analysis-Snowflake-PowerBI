# Agricultural Yield Analysis using Snowflake and Power BI

## ğŸ“Œ Project Overview
This project demonstrates an end-to-end analytics workflow using **Snowflake** as a cloud data warehouse and **Power BI** for data visualization and dashboarding.

The goal of the project is to analyze agricultural yield data across multiple dimensions such as **year, season, crop type, rainfall, temperature, humidity, and location**, and present insights through interactive dashboards.

---

## ğŸ–¼ï¸ Sample Dashboard â€“ Yield Analysis

Below is a sample view of the Yield Analysis report page:
ğŸ”— [View Dashboard(Google Drive)](https://drive.google.com/file/d/1gJtYTKPUUlT28AxNj715a6lWM_fjPA_W/view?usp=drive_link)

ğŸ”— [Dashboard Walkthrough (Google Drive)](https://drive.google.com/file/d/1qyqJzAYabnCBb9ESjjrPHR7nDodvML-v/view?usp=drive_link)

---

## âš ï¸ Disclaimer
This project follows an industry-style architecture where data is typically ingested from cloud storage (AWS S3) into Snowflake before being consumed by BI tools such as Power BI.

To avoid unnecessary cloud billing risks during learning, the AWS ingestion layer was **not implemented practically**. Instead, data was directly loaded into Snowflake using Snowflakeâ€™s **internal staging and data loading capabilities**.

The complete AWS-to-Snowflake ingestion process, including S3 bucket creation, file upload, IAM role creation, and integration concepts, has been **fully documented** to demonstrate conceptual understanding of the end-to-end data pipeline.

**Documented Architecture:**  
AWS S3 â†’ Snowflake â†’ Power BI  

**Implemented Architecture:**  
Local CSV â†’ Snowflake â†’ Power BI  

---

## ğŸ› ï¸ Tech Stack
- Snowflake (Cloud Data Warehouse)
- Power BI (Data Visualization)
- SQL (Data Transformation)
- CSV Dataset

---

## ğŸ—ï¸ Project Architecture
Local CSV file is ingested into Snowflake using internal staging, transformed using SQL, and visualized in Power BI.

Local CSV â†’ Snowflake â†’ Power BI

---

## ğŸ“‚ Data Modeling in Snowflake

### Database and Schema
```sql
CREATE OR REPLACE DATABASE PowerBI;
USE DATABASE PowerBI;

CREATE SCHEMA PBI_Data;
USE SCHEMA PBI_Data;
```

### Target Table
```sql
CREATE TABLE PBI_Dataset (
    Year INT,
    Location STRING,
    Area INT,
    Rainfall FLOAT,
    Temperature FLOAT,
    Soil_type STRING,
    Irrigation STRING,
    Yields INT,
    Humidity FLOAT,
    Crops STRING,
    Price INT,
    Season STRING
);
```
---

## ğŸ“¥ Data Loading

Data was loaded directly into Snowflake using Snowflake UI internal staging.

**Steps:**

- Navigate to Databases â†’ PowerBI â†’ PBI_Data â†’ Tables
- Select the table PBI_Dataset
- Click Load Data
- Upload the CSV file
- Snowflake automatically detects the file format and loads the data

---

## ğŸ”„ Data Transformation using Snowflake SQL

A replica table was created to safely apply transformations.
**Transformations Performed**
- Increased rainfall values by 10%
- Reduced area values by 10%
- Grouped years into logical buckets
- Categorized rainfall into Low, Mid, and High

---

## ğŸ¯ Key Learnings

- Snowflake database and schema design

- Internal staging and data ingestion

- SQL-based data transformations

- BI-friendly analytics modeling

- Power BI integration with Snowflake

- Real-world analytics workflow
